{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 100.0,
  "global_step": 111100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.45,
      "learning_rate": 4.977497749774978e-05,
      "loss": 3.2516,
      "step": 500
    },
    {
      "epoch": 0.9,
      "learning_rate": 4.954995499549955e-05,
      "loss": 3.0989,
      "step": 1000
    },
    {
      "epoch": 1.35,
      "learning_rate": 4.932493249324933e-05,
      "loss": 2.9235,
      "step": 1500
    },
    {
      "epoch": 1.8,
      "learning_rate": 4.9099909990999104e-05,
      "loss": 2.8309,
      "step": 2000
    },
    {
      "epoch": 2.25,
      "learning_rate": 4.887488748874888e-05,
      "loss": 2.6919,
      "step": 2500
    },
    {
      "epoch": 2.7,
      "learning_rate": 4.864986498649865e-05,
      "loss": 2.5834,
      "step": 3000
    },
    {
      "epoch": 3.15,
      "learning_rate": 4.842484248424843e-05,
      "loss": 2.4903,
      "step": 3500
    },
    {
      "epoch": 3.6,
      "learning_rate": 4.81998199819982e-05,
      "loss": 2.3601,
      "step": 4000
    },
    {
      "epoch": 4.05,
      "learning_rate": 4.797479747974798e-05,
      "loss": 2.316,
      "step": 4500
    },
    {
      "epoch": 4.5,
      "learning_rate": 4.774977497749775e-05,
      "loss": 2.1752,
      "step": 5000
    },
    {
      "epoch": 4.95,
      "learning_rate": 4.7524752475247525e-05,
      "loss": 2.1609,
      "step": 5500
    },
    {
      "epoch": 5.4,
      "learning_rate": 4.72997299729973e-05,
      "loss": 2.0326,
      "step": 6000
    },
    {
      "epoch": 5.85,
      "learning_rate": 4.7074707470747076e-05,
      "loss": 2.0261,
      "step": 6500
    },
    {
      "epoch": 6.3,
      "learning_rate": 4.684968496849685e-05,
      "loss": 1.9278,
      "step": 7000
    },
    {
      "epoch": 6.75,
      "learning_rate": 4.6624662466246627e-05,
      "loss": 1.9503,
      "step": 7500
    },
    {
      "epoch": 7.2,
      "learning_rate": 4.63996399639964e-05,
      "loss": 1.8529,
      "step": 8000
    },
    {
      "epoch": 7.65,
      "learning_rate": 4.617461746174618e-05,
      "loss": 1.7936,
      "step": 8500
    },
    {
      "epoch": 8.1,
      "learning_rate": 4.594959495949595e-05,
      "loss": 1.7735,
      "step": 9000
    },
    {
      "epoch": 8.55,
      "learning_rate": 4.572457245724573e-05,
      "loss": 1.6969,
      "step": 9500
    },
    {
      "epoch": 9.0,
      "learning_rate": 4.5499549954995503e-05,
      "loss": 1.7059,
      "step": 10000
    },
    {
      "epoch": 9.45,
      "learning_rate": 4.527452745274527e-05,
      "loss": 1.6084,
      "step": 10500
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.5049504950495054e-05,
      "loss": 1.6279,
      "step": 11000
    },
    {
      "epoch": 10.35,
      "learning_rate": 4.482448244824482e-05,
      "loss": 1.5545,
      "step": 11500
    },
    {
      "epoch": 10.8,
      "learning_rate": 4.4599459945994605e-05,
      "loss": 1.5515,
      "step": 12000
    },
    {
      "epoch": 11.25,
      "learning_rate": 4.4374437443744374e-05,
      "loss": 1.5056,
      "step": 12500
    },
    {
      "epoch": 11.7,
      "learning_rate": 4.414941494149415e-05,
      "loss": 1.483,
      "step": 13000
    },
    {
      "epoch": 12.15,
      "learning_rate": 4.3924392439243924e-05,
      "loss": 1.4608,
      "step": 13500
    },
    {
      "epoch": 12.6,
      "learning_rate": 4.36993699369937e-05,
      "loss": 1.4188,
      "step": 14000
    },
    {
      "epoch": 13.05,
      "learning_rate": 4.347434743474348e-05,
      "loss": 1.4274,
      "step": 14500
    },
    {
      "epoch": 13.5,
      "learning_rate": 4.324932493249325e-05,
      "loss": 1.3602,
      "step": 15000
    },
    {
      "epoch": 13.95,
      "learning_rate": 4.3024302430243026e-05,
      "loss": 1.3783,
      "step": 15500
    },
    {
      "epoch": 14.4,
      "learning_rate": 4.27992799279928e-05,
      "loss": 1.3147,
      "step": 16000
    },
    {
      "epoch": 14.85,
      "learning_rate": 4.257425742574258e-05,
      "loss": 1.3266,
      "step": 16500
    },
    {
      "epoch": 15.3,
      "learning_rate": 4.234923492349235e-05,
      "loss": 1.2798,
      "step": 17000
    },
    {
      "epoch": 15.75,
      "learning_rate": 4.212421242124213e-05,
      "loss": 1.276,
      "step": 17500
    },
    {
      "epoch": 16.2,
      "learning_rate": 4.1899189918991896e-05,
      "loss": 1.2529,
      "step": 18000
    },
    {
      "epoch": 16.65,
      "learning_rate": 4.167416741674168e-05,
      "loss": 1.2265,
      "step": 18500
    },
    {
      "epoch": 17.1,
      "learning_rate": 4.144914491449145e-05,
      "loss": 1.225,
      "step": 19000
    },
    {
      "epoch": 17.55,
      "learning_rate": 4.122412241224123e-05,
      "loss": 1.1987,
      "step": 19500
    },
    {
      "epoch": 18.0,
      "learning_rate": 4.0999099909991e-05,
      "loss": 1.1996,
      "step": 20000
    },
    {
      "epoch": 18.45,
      "learning_rate": 4.077407740774077e-05,
      "loss": 1.1379,
      "step": 20500
    },
    {
      "epoch": 18.9,
      "learning_rate": 4.0549054905490555e-05,
      "loss": 1.1595,
      "step": 21000
    },
    {
      "epoch": 19.35,
      "learning_rate": 4.0324032403240324e-05,
      "loss": 1.1166,
      "step": 21500
    },
    {
      "epoch": 19.8,
      "learning_rate": 4.0099009900990106e-05,
      "loss": 1.1167,
      "step": 22000
    },
    {
      "epoch": 20.25,
      "learning_rate": 3.9873987398739875e-05,
      "loss": 1.0888,
      "step": 22500
    },
    {
      "epoch": 20.7,
      "learning_rate": 3.964896489648965e-05,
      "loss": 1.0801,
      "step": 23000
    },
    {
      "epoch": 21.15,
      "learning_rate": 3.9423942394239426e-05,
      "loss": 1.0667,
      "step": 23500
    },
    {
      "epoch": 21.6,
      "learning_rate": 3.91989198919892e-05,
      "loss": 1.0396,
      "step": 24000
    },
    {
      "epoch": 22.05,
      "learning_rate": 3.8973897389738976e-05,
      "loss": 1.0478,
      "step": 24500
    },
    {
      "epoch": 22.5,
      "learning_rate": 3.874887488748875e-05,
      "loss": 1.0019,
      "step": 25000
    },
    {
      "epoch": 22.95,
      "learning_rate": 3.852385238523852e-05,
      "loss": 1.0218,
      "step": 25500
    },
    {
      "epoch": 23.4,
      "learning_rate": 3.82988298829883e-05,
      "loss": 0.9758,
      "step": 26000
    },
    {
      "epoch": 23.85,
      "learning_rate": 3.807380738073808e-05,
      "loss": 0.9867,
      "step": 26500
    },
    {
      "epoch": 24.3,
      "learning_rate": 3.784878487848785e-05,
      "loss": 0.9551,
      "step": 27000
    },
    {
      "epoch": 24.75,
      "learning_rate": 3.762376237623763e-05,
      "loss": 0.9536,
      "step": 27500
    },
    {
      "epoch": 25.2,
      "learning_rate": 3.73987398739874e-05,
      "loss": 0.9396,
      "step": 28000
    },
    {
      "epoch": 25.65,
      "learning_rate": 3.717371737173718e-05,
      "loss": 0.9214,
      "step": 28500
    },
    {
      "epoch": 26.1,
      "learning_rate": 3.694869486948695e-05,
      "loss": 0.9205,
      "step": 29000
    },
    {
      "epoch": 26.55,
      "learning_rate": 3.672367236723673e-05,
      "loss": 0.8905,
      "step": 29500
    },
    {
      "epoch": 27.0,
      "learning_rate": 3.64986498649865e-05,
      "loss": 0.9072,
      "step": 30000
    },
    {
      "epoch": 27.45,
      "learning_rate": 3.6273627362736274e-05,
      "loss": 0.8767,
      "step": 30500
    },
    {
      "epoch": 27.9,
      "learning_rate": 3.604860486048605e-05,
      "loss": 0.8767,
      "step": 31000
    },
    {
      "epoch": 28.35,
      "learning_rate": 3.5823582358235825e-05,
      "loss": 0.8439,
      "step": 31500
    },
    {
      "epoch": 28.8,
      "learning_rate": 3.55985598559856e-05,
      "loss": 0.8585,
      "step": 32000
    },
    {
      "epoch": 29.25,
      "learning_rate": 3.5373537353735376e-05,
      "loss": 0.839,
      "step": 32500
    },
    {
      "epoch": 29.7,
      "learning_rate": 3.514851485148515e-05,
      "loss": 0.825,
      "step": 33000
    },
    {
      "epoch": 30.15,
      "learning_rate": 3.492349234923493e-05,
      "loss": 0.8165,
      "step": 33500
    },
    {
      "epoch": 30.6,
      "learning_rate": 3.46984698469847e-05,
      "loss": 0.7932,
      "step": 34000
    },
    {
      "epoch": 31.05,
      "learning_rate": 3.447344734473448e-05,
      "loss": 0.8009,
      "step": 34500
    },
    {
      "epoch": 31.5,
      "learning_rate": 3.424842484248425e-05,
      "loss": 0.7655,
      "step": 35000
    },
    {
      "epoch": 31.95,
      "learning_rate": 3.402340234023402e-05,
      "loss": 0.7805,
      "step": 35500
    },
    {
      "epoch": 32.4,
      "learning_rate": 3.3798379837983804e-05,
      "loss": 0.7463,
      "step": 36000
    },
    {
      "epoch": 32.85,
      "learning_rate": 3.357335733573357e-05,
      "loss": 0.754,
      "step": 36500
    },
    {
      "epoch": 33.3,
      "learning_rate": 3.3348334833483354e-05,
      "loss": 0.7323,
      "step": 37000
    },
    {
      "epoch": 33.75,
      "learning_rate": 3.312331233123312e-05,
      "loss": 0.7284,
      "step": 37500
    },
    {
      "epoch": 34.2,
      "learning_rate": 3.28982898289829e-05,
      "loss": 0.7178,
      "step": 38000
    },
    {
      "epoch": 34.65,
      "learning_rate": 3.2673267326732674e-05,
      "loss": 0.7042,
      "step": 38500
    },
    {
      "epoch": 35.1,
      "learning_rate": 3.244824482448245e-05,
      "loss": 0.7057,
      "step": 39000
    },
    {
      "epoch": 35.55,
      "learning_rate": 3.2223222322232225e-05,
      "loss": 0.6792,
      "step": 39500
    },
    {
      "epoch": 36.0,
      "learning_rate": 3.1998199819982e-05,
      "loss": 0.6907,
      "step": 40000
    },
    {
      "epoch": 36.45,
      "learning_rate": 3.1773177317731775e-05,
      "loss": 0.6543,
      "step": 40500
    },
    {
      "epoch": 36.9,
      "learning_rate": 3.154815481548155e-05,
      "loss": 0.6682,
      "step": 41000
    },
    {
      "epoch": 37.35,
      "learning_rate": 3.1323132313231326e-05,
      "loss": 0.6411,
      "step": 41500
    },
    {
      "epoch": 37.8,
      "learning_rate": 3.10981098109811e-05,
      "loss": 0.644,
      "step": 42000
    },
    {
      "epoch": 38.25,
      "learning_rate": 3.087308730873088e-05,
      "loss": 0.6283,
      "step": 42500
    },
    {
      "epoch": 38.7,
      "learning_rate": 3.0648064806480646e-05,
      "loss": 0.6206,
      "step": 43000
    },
    {
      "epoch": 39.15,
      "learning_rate": 3.0423042304230424e-05,
      "loss": 0.6172,
      "step": 43500
    },
    {
      "epoch": 39.6,
      "learning_rate": 3.01980198019802e-05,
      "loss": 0.599,
      "step": 44000
    },
    {
      "epoch": 40.05,
      "learning_rate": 2.9972997299729975e-05,
      "loss": 0.6036,
      "step": 44500
    },
    {
      "epoch": 40.5,
      "learning_rate": 2.974797479747975e-05,
      "loss": 0.5771,
      "step": 45000
    },
    {
      "epoch": 40.95,
      "learning_rate": 2.9522952295229523e-05,
      "loss": 0.5871,
      "step": 45500
    },
    {
      "epoch": 41.4,
      "learning_rate": 2.92979297929793e-05,
      "loss": 0.5588,
      "step": 46000
    },
    {
      "epoch": 41.85,
      "learning_rate": 2.9072907290729073e-05,
      "loss": 0.5657,
      "step": 46500
    },
    {
      "epoch": 42.3,
      "learning_rate": 2.8847884788478852e-05,
      "loss": 0.5459,
      "step": 47000
    },
    {
      "epoch": 42.75,
      "learning_rate": 2.8622862286228624e-05,
      "loss": 0.5452,
      "step": 47500
    },
    {
      "epoch": 43.2,
      "learning_rate": 2.8397839783978396e-05,
      "loss": 0.5364,
      "step": 48000
    },
    {
      "epoch": 43.65,
      "learning_rate": 2.8172817281728175e-05,
      "loss": 0.5241,
      "step": 48500
    },
    {
      "epoch": 44.1,
      "learning_rate": 2.7947794779477947e-05,
      "loss": 0.5226,
      "step": 49000
    },
    {
      "epoch": 44.55,
      "learning_rate": 2.7722772277227726e-05,
      "loss": 0.5036,
      "step": 49500
    },
    {
      "epoch": 45.0,
      "learning_rate": 2.7497749774977498e-05,
      "loss": 0.5129,
      "step": 50000
    },
    {
      "epoch": 45.45,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 0.4827,
      "step": 50500
    },
    {
      "epoch": 45.9,
      "learning_rate": 2.7047704770477052e-05,
      "loss": 0.4932,
      "step": 51000
    },
    {
      "epoch": 46.35,
      "learning_rate": 2.6822682268226824e-05,
      "loss": 0.4704,
      "step": 51500
    },
    {
      "epoch": 46.8,
      "learning_rate": 2.6597659765976603e-05,
      "loss": 0.474,
      "step": 52000
    },
    {
      "epoch": 47.25,
      "learning_rate": 2.6372637263726375e-05,
      "loss": 0.4599,
      "step": 52500
    },
    {
      "epoch": 47.7,
      "learning_rate": 2.6147614761476147e-05,
      "loss": 0.4533,
      "step": 53000
    },
    {
      "epoch": 48.15,
      "learning_rate": 2.5922592259225925e-05,
      "loss": 0.4478,
      "step": 53500
    },
    {
      "epoch": 48.6,
      "learning_rate": 2.5697569756975697e-05,
      "loss": 0.4338,
      "step": 54000
    },
    {
      "epoch": 49.05,
      "learning_rate": 2.5472547254725476e-05,
      "loss": 0.438,
      "step": 54500
    },
    {
      "epoch": 49.5,
      "learning_rate": 2.5247524752475248e-05,
      "loss": 0.4153,
      "step": 55000
    },
    {
      "epoch": 49.95,
      "learning_rate": 2.502250225022502e-05,
      "loss": 0.4239,
      "step": 55500
    },
    {
      "epoch": 50.41,
      "learning_rate": 2.47974797479748e-05,
      "loss": 0.4,
      "step": 56000
    },
    {
      "epoch": 50.86,
      "learning_rate": 2.457245724572457e-05,
      "loss": 0.4053,
      "step": 56500
    },
    {
      "epoch": 51.31,
      "learning_rate": 2.434743474347435e-05,
      "loss": 0.3884,
      "step": 57000
    },
    {
      "epoch": 51.76,
      "learning_rate": 2.4122412241224125e-05,
      "loss": 0.3865,
      "step": 57500
    },
    {
      "epoch": 52.21,
      "learning_rate": 2.38973897389739e-05,
      "loss": 0.3796,
      "step": 58000
    },
    {
      "epoch": 52.66,
      "learning_rate": 2.3672367236723676e-05,
      "loss": 0.3693,
      "step": 58500
    },
    {
      "epoch": 53.11,
      "learning_rate": 2.3447344734473448e-05,
      "loss": 0.3691,
      "step": 59000
    },
    {
      "epoch": 53.56,
      "learning_rate": 2.3222322232223223e-05,
      "loss": 0.3523,
      "step": 59500
    },
    {
      "epoch": 54.01,
      "learning_rate": 2.2997299729973e-05,
      "loss": 0.3595,
      "step": 60000
    },
    {
      "epoch": 54.46,
      "learning_rate": 2.2772277227722774e-05,
      "loss": 0.3344,
      "step": 60500
    },
    {
      "epoch": 54.91,
      "learning_rate": 2.254725472547255e-05,
      "loss": 0.3424,
      "step": 61000
    },
    {
      "epoch": 55.36,
      "learning_rate": 2.232223222322232e-05,
      "loss": 0.3253,
      "step": 61500
    },
    {
      "epoch": 55.81,
      "learning_rate": 2.2097209720972097e-05,
      "loss": 0.3264,
      "step": 62000
    },
    {
      "epoch": 56.26,
      "learning_rate": 2.1872187218721872e-05,
      "loss": 0.3184,
      "step": 62500
    },
    {
      "epoch": 56.71,
      "learning_rate": 2.1647164716471648e-05,
      "loss": 0.3214,
      "step": 63000
    },
    {
      "epoch": 57.16,
      "learning_rate": 2.1422142214221423e-05,
      "loss": 0.3248,
      "step": 63500
    },
    {
      "epoch": 57.61,
      "learning_rate": 2.11971197119712e-05,
      "loss": 0.2986,
      "step": 64000
    },
    {
      "epoch": 58.06,
      "learning_rate": 2.0972097209720974e-05,
      "loss": 0.3006,
      "step": 64500
    },
    {
      "epoch": 58.51,
      "learning_rate": 2.074707470747075e-05,
      "loss": 0.282,
      "step": 65000
    },
    {
      "epoch": 58.96,
      "learning_rate": 2.0522052205220525e-05,
      "loss": 0.2912,
      "step": 65500
    },
    {
      "epoch": 59.41,
      "learning_rate": 2.02970297029703e-05,
      "loss": 0.2745,
      "step": 66000
    },
    {
      "epoch": 59.86,
      "learning_rate": 2.0072007200720072e-05,
      "loss": 0.2787,
      "step": 66500
    },
    {
      "epoch": 60.31,
      "learning_rate": 1.9846984698469848e-05,
      "loss": 0.2661,
      "step": 67000
    },
    {
      "epoch": 60.76,
      "learning_rate": 1.9621962196219623e-05,
      "loss": 0.2623,
      "step": 67500
    },
    {
      "epoch": 61.21,
      "learning_rate": 1.93969396939694e-05,
      "loss": 0.255,
      "step": 68000
    },
    {
      "epoch": 61.66,
      "learning_rate": 1.9171917191719174e-05,
      "loss": 0.2488,
      "step": 68500
    },
    {
      "epoch": 62.11,
      "learning_rate": 1.8946894689468946e-05,
      "loss": 0.2483,
      "step": 69000
    },
    {
      "epoch": 62.56,
      "learning_rate": 1.872187218721872e-05,
      "loss": 0.2359,
      "step": 69500
    },
    {
      "epoch": 63.01,
      "learning_rate": 1.8496849684968497e-05,
      "loss": 0.2409,
      "step": 70000
    },
    {
      "epoch": 63.46,
      "learning_rate": 1.8271827182718272e-05,
      "loss": 0.2247,
      "step": 70500
    },
    {
      "epoch": 63.91,
      "learning_rate": 1.8046804680468047e-05,
      "loss": 0.231,
      "step": 71000
    },
    {
      "epoch": 64.36,
      "learning_rate": 1.7821782178217823e-05,
      "loss": 0.2176,
      "step": 71500
    },
    {
      "epoch": 64.81,
      "learning_rate": 1.7596759675967598e-05,
      "loss": 0.2184,
      "step": 72000
    },
    {
      "epoch": 65.26,
      "learning_rate": 1.7371737173717373e-05,
      "loss": 0.2118,
      "step": 72500
    },
    {
      "epoch": 65.71,
      "learning_rate": 1.714671467146715e-05,
      "loss": 0.2075,
      "step": 73000
    },
    {
      "epoch": 66.16,
      "learning_rate": 1.692169216921692e-05,
      "loss": 0.206,
      "step": 73500
    },
    {
      "epoch": 66.61,
      "learning_rate": 1.6696669666966696e-05,
      "loss": 0.1985,
      "step": 74000
    },
    {
      "epoch": 67.06,
      "learning_rate": 1.647164716471647e-05,
      "loss": 0.2,
      "step": 74500
    },
    {
      "epoch": 67.51,
      "learning_rate": 1.6246624662466247e-05,
      "loss": 0.1893,
      "step": 75000
    },
    {
      "epoch": 67.96,
      "learning_rate": 1.6021602160216022e-05,
      "loss": 0.1939,
      "step": 75500
    },
    {
      "epoch": 68.41,
      "learning_rate": 1.5796579657965794e-05,
      "loss": 0.182,
      "step": 76000
    },
    {
      "epoch": 68.86,
      "learning_rate": 1.557155715571557e-05,
      "loss": 0.1854,
      "step": 76500
    },
    {
      "epoch": 69.31,
      "learning_rate": 1.534653465346535e-05,
      "loss": 0.1779,
      "step": 77000
    },
    {
      "epoch": 69.76,
      "learning_rate": 1.5121512151215122e-05,
      "loss": 0.1772,
      "step": 77500
    },
    {
      "epoch": 70.21,
      "learning_rate": 1.4896489648964898e-05,
      "loss": 0.174,
      "step": 78000
    },
    {
      "epoch": 70.66,
      "learning_rate": 1.4671467146714671e-05,
      "loss": 0.1686,
      "step": 78500
    },
    {
      "epoch": 71.11,
      "learning_rate": 1.4446444644464447e-05,
      "loss": 0.1689,
      "step": 79000
    },
    {
      "epoch": 71.56,
      "learning_rate": 1.4221422142214222e-05,
      "loss": 0.1627,
      "step": 79500
    },
    {
      "epoch": 72.01,
      "learning_rate": 1.3996399639963998e-05,
      "loss": 0.1658,
      "step": 80000
    },
    {
      "epoch": 72.46,
      "learning_rate": 1.3771377137713773e-05,
      "loss": 0.1554,
      "step": 80500
    },
    {
      "epoch": 72.91,
      "learning_rate": 1.3546354635463545e-05,
      "loss": 0.1583,
      "step": 81000
    },
    {
      "epoch": 73.36,
      "learning_rate": 1.332133213321332e-05,
      "loss": 0.1516,
      "step": 81500
    },
    {
      "epoch": 73.81,
      "learning_rate": 1.3096309630963097e-05,
      "loss": 0.1521,
      "step": 82000
    },
    {
      "epoch": 74.26,
      "learning_rate": 1.2871287128712873e-05,
      "loss": 0.1485,
      "step": 82500
    },
    {
      "epoch": 74.71,
      "learning_rate": 1.2646264626462648e-05,
      "loss": 0.1465,
      "step": 83000
    },
    {
      "epoch": 75.16,
      "learning_rate": 1.2421242124212422e-05,
      "loss": 0.145,
      "step": 83500
    },
    {
      "epoch": 75.61,
      "learning_rate": 1.2196219621962197e-05,
      "loss": 0.1408,
      "step": 84000
    },
    {
      "epoch": 76.06,
      "learning_rate": 1.1971197119711971e-05,
      "loss": 0.142,
      "step": 84500
    },
    {
      "epoch": 76.51,
      "learning_rate": 1.1746174617461746e-05,
      "loss": 0.1363,
      "step": 85000
    },
    {
      "epoch": 76.96,
      "learning_rate": 1.1521152115211522e-05,
      "loss": 0.1379,
      "step": 85500
    },
    {
      "epoch": 77.41,
      "learning_rate": 1.1296129612961297e-05,
      "loss": 0.1322,
      "step": 86000
    },
    {
      "epoch": 77.86,
      "learning_rate": 1.1071107110711073e-05,
      "loss": 0.1342,
      "step": 86500
    },
    {
      "epoch": 78.31,
      "learning_rate": 1.0846084608460846e-05,
      "loss": 0.1299,
      "step": 87000
    },
    {
      "epoch": 78.76,
      "learning_rate": 1.0621062106210622e-05,
      "loss": 0.1293,
      "step": 87500
    },
    {
      "epoch": 79.21,
      "learning_rate": 1.0396039603960395e-05,
      "loss": 0.1274,
      "step": 88000
    },
    {
      "epoch": 79.66,
      "learning_rate": 1.017101710171017e-05,
      "loss": 0.125,
      "step": 88500
    },
    {
      "epoch": 80.11,
      "learning_rate": 9.945994599459948e-06,
      "loss": 0.1247,
      "step": 89000
    },
    {
      "epoch": 80.56,
      "learning_rate": 9.720972097209722e-06,
      "loss": 0.1208,
      "step": 89500
    },
    {
      "epoch": 81.01,
      "learning_rate": 9.495949594959497e-06,
      "loss": 0.1236,
      "step": 90000
    },
    {
      "epoch": 81.46,
      "learning_rate": 9.27092709270927e-06,
      "loss": 0.1175,
      "step": 90500
    },
    {
      "epoch": 81.91,
      "learning_rate": 9.045904590459046e-06,
      "loss": 0.1196,
      "step": 91000
    },
    {
      "epoch": 82.36,
      "learning_rate": 8.820882088208822e-06,
      "loss": 0.1154,
      "step": 91500
    },
    {
      "epoch": 82.81,
      "learning_rate": 8.595859585958597e-06,
      "loss": 0.1157,
      "step": 92000
    },
    {
      "epoch": 83.26,
      "learning_rate": 8.370837083708372e-06,
      "loss": 0.1143,
      "step": 92500
    },
    {
      "epoch": 83.71,
      "learning_rate": 8.145814581458146e-06,
      "loss": 0.1127,
      "step": 93000
    },
    {
      "epoch": 84.16,
      "learning_rate": 7.920792079207921e-06,
      "loss": 0.112,
      "step": 93500
    },
    {
      "epoch": 84.61,
      "learning_rate": 7.695769576957697e-06,
      "loss": 0.1104,
      "step": 94000
    },
    {
      "epoch": 85.06,
      "learning_rate": 7.470747074707471e-06,
      "loss": 0.1108,
      "step": 94500
    },
    {
      "epoch": 85.51,
      "learning_rate": 7.245724572457247e-06,
      "loss": 0.1072,
      "step": 95000
    },
    {
      "epoch": 85.96,
      "learning_rate": 7.02070207020702e-06,
      "loss": 0.1088,
      "step": 95500
    },
    {
      "epoch": 86.41,
      "learning_rate": 6.795679567956796e-06,
      "loss": 0.1052,
      "step": 96000
    },
    {
      "epoch": 86.86,
      "learning_rate": 6.570657065706572e-06,
      "loss": 0.1057,
      "step": 96500
    },
    {
      "epoch": 87.31,
      "learning_rate": 6.345634563456346e-06,
      "loss": 0.104,
      "step": 97000
    },
    {
      "epoch": 87.76,
      "learning_rate": 6.12061206120612e-06,
      "loss": 0.104,
      "step": 97500
    },
    {
      "epoch": 88.21,
      "learning_rate": 5.8955895589558965e-06,
      "loss": 0.1028,
      "step": 98000
    },
    {
      "epoch": 88.66,
      "learning_rate": 5.670567056705671e-06,
      "loss": 0.1018,
      "step": 98500
    },
    {
      "epoch": 89.11,
      "learning_rate": 5.445544554455446e-06,
      "loss": 0.1014,
      "step": 99000
    },
    {
      "epoch": 89.56,
      "learning_rate": 5.220522052205221e-06,
      "loss": 0.0997,
      "step": 99500
    },
    {
      "epoch": 90.01,
      "learning_rate": 4.995499549954996e-06,
      "loss": 0.1004,
      "step": 100000
    },
    {
      "epoch": 90.46,
      "learning_rate": 4.770477047704771e-06,
      "loss": 0.0978,
      "step": 100500
    },
    {
      "epoch": 90.91,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.0986,
      "step": 101000
    },
    {
      "epoch": 91.36,
      "learning_rate": 4.320432043204321e-06,
      "loss": 0.097,
      "step": 101500
    },
    {
      "epoch": 91.81,
      "learning_rate": 4.0954095409540955e-06,
      "loss": 0.0976,
      "step": 102000
    },
    {
      "epoch": 92.26,
      "learning_rate": 3.87038703870387e-06,
      "loss": 0.096,
      "step": 102500
    },
    {
      "epoch": 92.71,
      "learning_rate": 3.645364536453646e-06,
      "loss": 0.0959,
      "step": 103000
    },
    {
      "epoch": 93.16,
      "learning_rate": 3.420342034203421e-06,
      "loss": 0.0947,
      "step": 103500
    },
    {
      "epoch": 93.61,
      "learning_rate": 3.1953195319531953e-06,
      "loss": 0.0944,
      "step": 104000
    },
    {
      "epoch": 94.06,
      "learning_rate": 2.9702970297029703e-06,
      "loss": 0.0946,
      "step": 104500
    },
    {
      "epoch": 94.51,
      "learning_rate": 2.7452745274527453e-06,
      "loss": 0.0932,
      "step": 105000
    },
    {
      "epoch": 94.96,
      "learning_rate": 2.5202520252025202e-06,
      "loss": 0.0936,
      "step": 105500
    },
    {
      "epoch": 95.41,
      "learning_rate": 2.2952295229522956e-06,
      "loss": 0.0927,
      "step": 106000
    },
    {
      "epoch": 95.86,
      "learning_rate": 2.07020702070207e-06,
      "loss": 0.092,
      "step": 106500
    },
    {
      "epoch": 96.31,
      "learning_rate": 1.8451845184518452e-06,
      "loss": 0.0916,
      "step": 107000
    },
    {
      "epoch": 96.76,
      "learning_rate": 1.6201620162016203e-06,
      "loss": 0.0913,
      "step": 107500
    },
    {
      "epoch": 97.21,
      "learning_rate": 1.395139513951395e-06,
      "loss": 0.0913,
      "step": 108000
    },
    {
      "epoch": 97.66,
      "learning_rate": 1.17011701170117e-06,
      "loss": 0.0908,
      "step": 108500
    },
    {
      "epoch": 98.11,
      "learning_rate": 9.450945094509451e-07,
      "loss": 0.0902,
      "step": 109000
    },
    {
      "epoch": 98.56,
      "learning_rate": 7.200720072007201e-07,
      "loss": 0.0903,
      "step": 109500
    },
    {
      "epoch": 99.01,
      "learning_rate": 4.950495049504951e-07,
      "loss": 0.0904,
      "step": 110000
    },
    {
      "epoch": 99.46,
      "learning_rate": 2.7002700270027006e-07,
      "loss": 0.0897,
      "step": 110500
    },
    {
      "epoch": 99.91,
      "learning_rate": 4.500450045004501e-08,
      "loss": 0.0899,
      "step": 111000
    },
    {
      "epoch": 100.0,
      "step": 111100,
      "total_flos": 8.250576970186752e+17,
      "train_loss": 0.6565183450937486,
      "train_runtime": 443642.6601,
      "train_samples_per_second": 1.001,
      "train_steps_per_second": 0.25
    }
  ],
  "max_steps": 111100,
  "num_train_epochs": 100,
  "total_flos": 8.250576970186752e+17,
  "trial_name": null,
  "trial_params": null
}
